# ğŸ•µï¸â€â™‚ï¸ Deepfake Detection System

## ğŸ“Œ Project Overview
The **Deepfake Detection System** is a machine learning-based application designed to identify manipulated videos (deepfakes) with high accuracy. In an era where digital misinformation is rampant, this tool helps in verifying the authenticity of video content by analyzing spatial and temporal features.

This project utilizes a **CNN-LSTM (Convolutional Neural Network - Long Short-Term Memory)** architecture. The CNN extracts spatial features from individual video frames, while the LSTM captures temporal inconsistencies across frame sequences, making it robust against frame-by-frame manipulation.

## ğŸš€ Features
- **Deepfake Classification**: accurately classifies videos as "Real" or "Fake".
- **Spatiotemporal Analysis**: Combines CNN (ResNet50) and LSTM for robust detection.
- **Web Interface**: User-friendly Flask-based web app for uploading and testing videos.
- **REST API**: `/predict` endpoint for integrating detection capabilities into other applications.
- **Data Augmentation**: Scripts included for GAN-based data augmentation.

## ğŸ› ï¸ Tech Stack
- **Language**: Python 3.8+
- **Deep Learning Framework**: PyTorch
- **Web Framework**: Flask
- **Data Processing**: OpenCV, NumPy, Pillow, Albumentations
- **Compute**: CUDA / MPS (Metal Performance Shaders for Mac) support

## ğŸ“‚ Project Structure
```
Deepfake Detection/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py                # Flask API application
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html        # Web frontend
â”œâ”€â”€ models/                   # Directory for saving trained models
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_cnn_lstm.py     # Main training script
â”‚   â”œâ”€â”€ train_gan.py          # GAN training script (experimental)
â”‚   â””â”€â”€ test_data_loading.py  # Utility to verify data loading
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py        # PyTorch Dataset class
â”‚   â”‚   â”œâ”€â”€ transforms.py     # Image transformations
â”‚   â”‚   â””â”€â”€ video_utils.py    # Video frame extraction logic
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ cnn_lstm.py       # CNN-LSTM model architecture
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ .gitignore                # Git ignore rules
```

## ğŸ“Š Dataset
The model is trained on the **Deepfake Dataset** by Tushar Padhy.
**[Download via Kaggle](https://www.kaggle.com/datasets/tusharpadhy/deepfake-dataset)**

### Data Organization
After downloading, extract the dataset into the project root. Your directory should look like this:
```
Deepfake Detection/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Fake/  # Contains fake videos/frames
â”‚   â””â”€â”€ Real/  # Contains real videos/frames
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ Fake/
â”‚   â””â”€â”€ Real/
```

## âš™ï¸ Installation & Setup

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/Vedansh-rai/Deepfake_Detection.git
    cd Deepfake_Detection
    ```

2.  **Create a Virtual Environment (Optional but Recommended)**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

## ğŸ‹ï¸â€â™‚ï¸ Training the Model

To train the CNN-LSTM model from scratch, run the following command:

```bash
python scripts/train_cnn_lstm.py --epochs 10 --batch_size 8 --learning_rate 0.0001
```

**Arguments:**
- `--epochs`: Number of training epochs (default: 10)
- `--batch_size`: Batch size for training (default: 8)
- `--num_frames`: Number of frames to extract per video (default: 20)
- `--checkpoint_dir`: Directory to save model checkpoints (default: `models`)

_Note: The script automatically detects if a GPU (CUDA) or Mac MPS is available and uses it for faster training._

## ğŸŒ Running the Web Application

Once the model is trained (or if you have a pre-trained model in `models/best_model.pth`), you can launch the web interface:

1.  **Start the Flask Server**
    ```bash
    python api/app.py
    ```

2.  **Access the App**
    Open your web browser and go to: `http://127.0.0.1:5000`

3.  **Upload & Predict**
    - Click "Choose File" to select a video (`.mp4`, `.avi`, `.mov`).
    - Click "Analyze Video".
    - View the prediction ("Real" or "Fake") and the confidence score.

## ğŸ§  Model Architecture Details
The system uses a hybrid architecture:
1.  **ResNet50 (Pre-trained)**: Acts as the feature extractor. We remove the fully connected top layers and use the convolutional output to represent each frame.
2.  **LSTM (Long Short-Term Memory)**: Takes the sequence of feature vectors from ResNet50. It processes the temporal evolution of features to detect anomalies that occur over time (e.g., flickering, unnatural movements).
3.  **Classification Head**: A fully connected layer maps the final LSTM output to a binary probability score.

## ğŸ¤ Contributing
Contributions are welcome! Please open an issue or submit a pull request for any improvements.

## ğŸ“œ License
This project is open-source and available under the MIT License.

## ğŸ‘¤ Author
**Vedansh Rai**
- [GitHub](https://github.com/Vedansh-rai)
